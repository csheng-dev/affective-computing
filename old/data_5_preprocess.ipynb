{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e284b7-23ca-44be-b42c-a954dad80e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873e6560-82c7-472f-a4b9-5bf2bba22c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_1\n",
      "subject_10\n",
      "subject_11\n",
      "subject_12\n",
      "subject_13\n",
      "subject_14\n",
      "subject_15\n",
      "subject_16\n",
      "subject_17\n",
      "subject_18\n",
      "subject_19\n",
      "subject_2\n",
      "subject_20\n",
      "subject_21\n",
      "subject_22\n",
      "subject_23\n",
      "subject_3\n",
      "subject_4\n",
      "subject_5\n",
      "subject_6\n",
      "subject_7\n",
      "subject_8\n",
      "subject_9\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the target directory\n",
    "base_path = \"C:/Users/Ally/Desktop/sheng/data/5/MEFAR\"\n",
    "\n",
    "# Get a list of all subdirectories in \"1\"\n",
    "subject_dirs = [name for name in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, name))]\n",
    "\n",
    "# Print each subdirectory name\n",
    "for subdir in subject_dirs:\n",
    "    print(subdir)\n",
    "    \n",
    "chunks_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e795883-8656-440f-b150-18f44b66e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(subject_dirs)):\n",
    "    subject_dirs[j]\n",
    "    \n",
    "    term_dirs = os.listdir(os.path.join(base_path, subject_dirs[j]))\n",
    "    for k in range(len(term_dirs)):\n",
    "\n",
    "        BVP_path = os.path.join(base_path, subject_dirs[j], term_dirs[k], \"BVP.csv\")\n",
    "        EDA_path = os.path.join(base_path, subject_dirs[j], term_dirs[k], \"EDA.csv\")\n",
    "        TEMP_path = os.path.join(base_path, subject_dirs[j], term_dirs[k], \"TEMP.csv\")\n",
    "\n",
    "        # Read the CSV file\n",
    "        df_BVP = pd.read_csv(BVP_path, header=None)\n",
    "        df_EDA = pd.read_csv(EDA_path, header=None)\n",
    "        df_TEMP = pd.read_csv(TEMP_path, header=None)\n",
    "\n",
    "        '''\n",
    "        if df_BVP.iloc[0,0] == df_EDA.iloc[0,0] and df_BVP.iloc[0,0] == df_TEMP.iloc[0,0]:\n",
    "            print(1)\n",
    "        else:\n",
    "            print(0)\n",
    "        '''\n",
    "        \n",
    "        df_BVP = df_BVP.iloc[2:].reset_index(drop=True)\n",
    "        df_EDA = df_EDA.iloc[2:].reset_index(drop=True)\n",
    "        df_TEMP = df_TEMP.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "        # downsample BVP to 32 hz\n",
    "        df_BVP = df_BVP.iloc[::2].reset_index(drop=True)\n",
    "        df_EDA = df_EDA.loc[df_EDA.index.repeat(8)].reset_index(drop=True)\n",
    "        df_TEMP = df_TEMP.loc[df_TEMP.index.repeat(8)].reset_index(drop=True)\n",
    "\n",
    "        # combine all three df into one data frame\n",
    "        # Step 1: Find the minimum number of rows\n",
    "        min_rows = min(len(df_BVP), len(df_EDA), len(df_TEMP))\n",
    "\n",
    "        # Step 2: Cut each dataframe to the minimum number of rows\n",
    "        df_BVP_cut = df_BVP.iloc[:min_rows].reset_index(drop=True)\n",
    "        df_EDA_cut = df_EDA.iloc[:min_rows].reset_index(drop=True)\n",
    "        df_TEMP_cut = df_TEMP.iloc[:min_rows].reset_index(drop=True)\n",
    "\n",
    "        # Step 3: combine columns\n",
    "        df= pd.concat([df_BVP_cut, df_EDA_cut, df_TEMP_cut], axis=1)\n",
    "    \n",
    "        # assign column names\n",
    "        df.columns = ['BVP', 'EDA', 'TEMP']\n",
    "\n",
    "        # set index as a column named \"time\"\n",
    "        df = df.reset_index().rename(columns={'index': 'time'})\n",
    "        df['subject'] = subject_dirs[j]\n",
    "\n",
    "        # chunk df into chunks of 4 seconds with 1 second overlap\n",
    "        # Parameters\n",
    "        fs = 32              # Sampling frequency (Hz)\n",
    "        chunk_duration = 4   # seconds\n",
    "        overlap_duration = 1 # seconds\n",
    "\n",
    "        chunk_size = chunk_duration * fs\n",
    "        overlap_size = overlap_duration * fs\n",
    "        step_size = chunk_size - overlap_size  # How many rows to move forward for each new chunk\n",
    "\n",
    "        # Store all chunks\n",
    "        chunks = []\n",
    "\n",
    "        # Go through the DataFrame\n",
    "        for start in range(0, len(df) - chunk_size + 1, step_size):\n",
    "            chunk = df.iloc[start : start + chunk_size].reset_index(drop=True)\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        # Now `chunks` is a list of DataFrames, each 128 rows, overlapping by 32 rows\n",
    "\n",
    "        chunks_all.append(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be0add9c-6625-4589-8f1d-dbb52a87d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks_all):\n",
    "    pd.concat(chunk, axis = 0).reset_index(drop = True).to_csv(f'chunk_{i}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1696bf7b-8c94-4529-95c7-220bd2ed9d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b23a57-a7f7-42f8-86d6-893fbaba0b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8927de-ee60-4279-8179-8bd8902142a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff808c43-88b7-4018-affc-40ff3b5f5878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
